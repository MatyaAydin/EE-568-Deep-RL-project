{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee65268f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-03 01:15:31,973] A new study created in memory with name: no-name-20c4db57-d27c-4e86-8652-a8092e59bbbd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5000, episode_reward=-1769.64 +/- 80.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-03 01:18:22,136] Trial 0 finished with value: -2.0927460193634033 and parameters: {'learning_rate': 2.5497540087101378e-05, 'batch_size': 256, 'buffer_size': 10000, 'learning_starts': 1000, 'train_freq': 12, 'gradient_steps': 5, 'net_arch': [512, 256], 'tau': 0.017726513288668456}. Best is trial 0 with value: -2.0927460193634033.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=10000, episode_reward=-1484.94 +/- 144.76\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Best trial:\n",
      "Value: -2.0927460193634033\n",
      "Params:\n",
      "    learning_rate: 2.5497540087101378e-05\n",
      "    batch_size: 256\n",
      "    buffer_size: 10000\n",
      "    learning_starts: 1000\n",
      "    train_freq: 12\n",
      "    gradient_steps: 5\n",
      "    net_arch: [512, 256]\n",
      "    tau: 0.017726513288668456\n",
      "Optimization completed.\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import TD3, SAC, PPO\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import os\n",
    "import torch\n",
    "import kaleido\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Define the evaluation function\n",
    "def evaluate_model(model, env, n_episodes=10):\n",
    "    \"\"\"\n",
    "    Evaluate a RL model\n",
    "    :param model: (BaseAlgorithm) the RL agent\n",
    "    :param env: (gym.Env) the gym environment\n",
    "    :param n_episodes: (int) number of episodes to evaluate\n",
    "    :return: (float) mean reward\n",
    "    \"\"\"\n",
    "    episode_rewards = []\n",
    "    for _ in range(n_episodes):\n",
    "        obs = env.reset()\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, terminated, truncated = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            episode_reward += reward\n",
    "        episode_rewards.append(episode_reward)\n",
    "    return np.mean(episode_rewards)\n",
    "\n",
    "# 2. Define the hyperparameter optimization objective\n",
    "def objective(trial):\n",
    "    # Create environment\n",
    "    env = gym.make(\"Pendulum-v1\")\n",
    "    env = Monitor(env)  # For tracking rewards\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    \n",
    "    # Sample hyperparameters\n",
    "    hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [128, 256]),\n",
    "        'buffer_size': trial.suggest_categorical('buffer_size', [int(1e4), int(1e3)]),\n",
    "        'learning_starts': trial.suggest_categorical('learning_starts', [100, 1000]),\n",
    "        'train_freq': trial.suggest_int('train_freq', 1, 20),\n",
    "        'gradient_steps': trial.suggest_int('gradient_steps', 1, 10),\n",
    "        'policy_kwargs': {\n",
    "            'net_arch': trial.suggest_categorical('net_arch', [[64, 64], [512, 256]])\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Algorithm-specific parameters\n",
    "    if algo == 'TD3':\n",
    "        hyperparams['action_noise'] = OrnsteinUhlenbeckActionNoise(\n",
    "            mean=np.zeros(env.action_space.shape[-1]),\n",
    "            sigma=0.5 * np.ones(env.action_space.shape[-1])\n",
    "        )\n",
    "        hyperparams['tau'] = trial.suggest_float('tau', 0.001, 0.1)\n",
    "    elif algo == 'SAC':\n",
    "        hyperparams['ent_coef'] = trial.suggest_categorical('ent_coef', ['auto', 0.01, 0.1])\n",
    "        hyperparams['tau'] = trial.suggest_float('tau', 0.001, 0.1)\n",
    "    elif algo == 'PPO':\n",
    "        hyperparams['n_steps'] = trial.suggest_categorical('n_steps', [64, 128, 256, 512, 1024, 2048])\n",
    "        hyperparams['gae_lambda'] = trial.suggest_float('gae_lambda', 0.8, 0.99)\n",
    "        hyperparams['clip_range'] = trial.suggest_float('clip_range', 0.1, 0.4)\n",
    "    \n",
    "    # Create model\n",
    "    if algo == 'TD3':\n",
    "        model = TD3(\"MlpPolicy\", env, verbose=0, **hyperparams)\n",
    "    elif algo == 'SAC':\n",
    "        model = SAC(\"MlpPolicy\", env, verbose=0, **hyperparams)\n",
    "    elif algo == 'PPO':\n",
    "        model = PPO(\"MlpPolicy\", env, verbose=0, **hyperparams)\n",
    "    \n",
    "    # Train the model\n",
    "    eval_callback = EvalCallback(\n",
    "        env,\n",
    "        # best_model_save_path=f\"./logs/{algo}/\",\n",
    "        log_path=f\"./logs/{algo}/\",\n",
    "        eval_freq=5000,\n",
    "        deterministic=True,\n",
    "        render=False\n",
    "    )\n",
    "    \n",
    "    model.learn(total_timesteps=10000, callback=eval_callback)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mean_reward = evaluate_model(model, env)\n",
    "    \n",
    "    # Clean up\n",
    "    del model\n",
    "    env.close()\n",
    "    \n",
    "    return mean_reward\n",
    "\n",
    "# 3. Run the optimization\n",
    "def optimize_hyperparams(algo, n_trials=20):\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"Value: {trial.value}\")\n",
    "    print(\"Params:\")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "    \n",
    "    # Save best parameters\n",
    "    with open(f\"best_params_{algo}.txt\", \"w\") as f:\n",
    "        f.write(str(trial.params))\n",
    "    \n",
    "    return study\n",
    "\n",
    "# 4. Plotting functions\n",
    "def plot_learning_curve(log_dir, algo):\n",
    "    \"\"\"\n",
    "    Plot the learning curve from Monitor logs\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Load all Monitor logs\n",
    "    df = pd.read_csv(f\"{log_dir}/monitor.csv\", skiprows=1)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df['r'], label='Episode Reward')\n",
    "    plt.plot(df['r'].rolling(10).mean(), label='Rolling Mean (10)')\n",
    "    plt.xlabel('Timesteps')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.title(f'{algo} Learning Curve')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(f'{algo}_learning_curve.png')\n",
    "\n",
    "def plot_reward_over_steps(study, algo):\n",
    "    \"\"\"\n",
    "    Plot reward over optimization steps\n",
    "    \"\"\"\n",
    "    fig = plot_optimization_history(study)\n",
    "    fig.update_layout(title=f'{algo} Optimization History')\n",
    "    print(\"hello\")\n",
    "    # fig.write_image(f\"{algo}_optimization_history.png\")\n",
    "\n",
    "\n",
    "algo = 'TD3'\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(f\"./logs/{algo}\", exist_ok=True)\n",
    "\n",
    "# Run hyperparameter optimization\n",
    "study = optimize_hyperparams(algo, n_trials=2)\n",
    "print(\"Optimization completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "620fedd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "Plotting optimization history.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot evaluate parameter importances with only a single trial.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlotting optimization history.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# plot_learning_curve(f\"./logs/{algo}\", algo)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Visualize parameter importance\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m fig \u001b[38;5;241m=\u001b[39m plot_param_importances(study)\n\u001b[0;32m      7\u001b[0m fig\u001b[38;5;241m.\u001b[39mupdate_layout(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malgo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Parameter Importance\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# fig.write_image(f\"{algo}_param_importance.png\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hasse\\anaconda3\\envs\\ada\\Lib\\site-packages\\optuna\\visualization\\_param_importances.py:168\u001b[0m, in \u001b[0;36mplot_param_importances\u001b[1;34m(study, evaluator, params, target, target_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Plot hyperparameter importances.\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m.. seealso::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    A :class:`plotly.graph_objects.Figure` object.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m _imports\u001b[38;5;241m.\u001b[39mcheck()\n\u001b[1;32m--> 168\u001b[0m importances_infos \u001b[38;5;241m=\u001b[39m _get_importances_infos(study, evaluator, params, target, target_name)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_importances_plot(importances_infos, study)\n",
      "File \u001b[1;32mc:\\Users\\hasse\\anaconda3\\envs\\ada\\Lib\\site-packages\\optuna\\visualization\\_param_importances.py:82\u001b[0m, in \u001b[0;36m_get_importances_infos\u001b[1;34m(study, evaluator, params, target, target_name)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m study\u001b[38;5;241m.\u001b[39m_is_multi_objective():\n\u001b[0;32m     80\u001b[0m     target_name \u001b[38;5;241m=\u001b[39m metric_names[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m metric_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m target \u001b[38;5;28;01melse\u001b[39;00m target_name\n\u001b[0;32m     81\u001b[0m     importances_infos: \u001b[38;5;28mtuple\u001b[39m[_ImportancesInfo, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m---> 82\u001b[0m         _get_importances_info(\n\u001b[0;32m     83\u001b[0m             study,\n\u001b[0;32m     84\u001b[0m             evaluator,\n\u001b[0;32m     85\u001b[0m             params,\n\u001b[0;32m     86\u001b[0m             target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[0;32m     87\u001b[0m             target_name\u001b[38;5;241m=\u001b[39mtarget_name,\n\u001b[0;32m     88\u001b[0m         ),\n\u001b[0;32m     89\u001b[0m     )\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     n_objectives \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(study\u001b[38;5;241m.\u001b[39mdirections)\n",
      "File \u001b[1;32mc:\\Users\\hasse\\anaconda3\\envs\\ada\\Lib\\site-packages\\optuna\\visualization\\_param_importances.py:54\u001b[0m, in \u001b[0;36m_get_importances_info\u001b[1;34m(study, evaluator, params, target, target_name)\u001b[0m\n\u001b[0;32m     46\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudy instance does not contain completed trials.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ImportancesInfo(\n\u001b[0;32m     48\u001b[0m         importance_values\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m     49\u001b[0m         param_names\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m     50\u001b[0m         importance_labels\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m     51\u001b[0m         target_name\u001b[38;5;241m=\u001b[39mtarget_name,\n\u001b[0;32m     52\u001b[0m     )\n\u001b[1;32m---> 54\u001b[0m importances \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mimportance\u001b[38;5;241m.\u001b[39mget_param_importances(\n\u001b[0;32m     55\u001b[0m     study, evaluator\u001b[38;5;241m=\u001b[39mevaluator, params\u001b[38;5;241m=\u001b[39mparams, target\u001b[38;5;241m=\u001b[39mtarget\n\u001b[0;32m     56\u001b[0m )\n\u001b[0;32m     58\u001b[0m importances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mlist\u001b[39m(importances\u001b[38;5;241m.\u001b[39mitems())))\n\u001b[0;32m     59\u001b[0m importance_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(importances\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[1;32mc:\\Users\\hasse\\anaconda3\\envs\\ada\\Lib\\site-packages\\optuna\\importance\\__init__.py:111\u001b[0m, in \u001b[0;36mget_param_importances\u001b[1;34m(study, evaluator, params, target, normalize)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(evaluator, BaseImportanceEvaluator):\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluator must be a subclass of BaseImportanceEvaluator.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 111\u001b[0m res \u001b[38;5;241m=\u001b[39m evaluator\u001b[38;5;241m.\u001b[39mevaluate(study, params\u001b[38;5;241m=\u001b[39mparams, target\u001b[38;5;241m=\u001b[39mtarget)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[0;32m    113\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(res\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[1;32mc:\\Users\\hasse\\anaconda3\\envs\\ada\\Lib\\site-packages\\optuna\\importance\\_fanova\\_evaluator.py:89\u001b[0m, in \u001b[0;36mFanovaImportanceEvaluator.evaluate\u001b[1;34m(self, study, params, target)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m study\u001b[38;5;241m.\u001b[39m_is_multi_objective():\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf the `study` is being used for multi-objective optimization, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease specify the `target`. For example, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`target=lambda t: t.values[0]` for the first objective value.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m     )\n\u001b[1;32m---> 89\u001b[0m distributions \u001b[38;5;241m=\u001b[39m _get_distributions(study, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(distributions\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32mc:\\Users\\hasse\\anaconda3\\envs\\ada\\Lib\\site-packages\\optuna\\importance\\_base.py:69\u001b[0m, in \u001b[0;36m_get_distributions\u001b[1;34m(study, params)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_distributions\u001b[39m(study: Study, params: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseDistribution]:\n\u001b[0;32m     68\u001b[0m     completed_trials \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mget_trials(deepcopy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, states\u001b[38;5;241m=\u001b[39m(TrialState\u001b[38;5;241m.\u001b[39mCOMPLETE,))\n\u001b[1;32m---> 69\u001b[0m     _check_evaluate_args(completed_trials, params)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m intersection_search_space(study\u001b[38;5;241m.\u001b[39mget_trials(deepcopy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\hasse\\anaconda3\\envs\\ada\\Lib\\site-packages\\optuna\\importance\\_base.py:114\u001b[0m, in \u001b[0;36m_check_evaluate_args\u001b[1;34m(completed_trials, params)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot evaluate parameter importances without completed trials.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(completed_trials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot evaluate parameter importances with only a single trial.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(params, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot evaluate parameter importances with only a single trial."
     ]
    }
   ],
   "source": [
    "\n",
    "# Plot results\n",
    "plot_reward_over_steps(study, algo) \n",
    "print(\"Plotting optimization history.\")\n",
    "# plot_learning_curve(f\"./logs/{algo}\", algo)\n",
    "# Visualize parameter importance\n",
    "fig = plot_param_importances(study)\n",
    "fig.update_layout(title=f'{algo} Parameter Importance')\n",
    "# fig.write_image(f\"{algo}_param_importance.png\")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
